# image_captioning

Text Generation from image<br/>
By Kruti Thukral (012586041)<br/>
Reference paper<br/>
- Show and Tell: A Neural Image Caption Generator Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3156-3164

Reference code snippet
- https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8
As per the paper, a simple encoder-decoder architecture composed of a CNN and RNN can be used to generate text from an image.

Youtube link for individual project presentation and project details
- https://www.youtube.com/watch?v=y9f2BcCA-Xo&feature=youtu.be

Github link for project implementation
- https://github.com/kruti-thukral/image_captioning

Dataset can be downloaded from https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/<br/>
Datasets that need to be downloaded from above link are
- Flickr8k_Dataset.zip
- Flickr8k_text.zip

Pre-trained Glove embeddings can be downloaded from
- https://nlp.stanford.edu/projects/glove/
- glove.6B.zip from above link was used in the project
